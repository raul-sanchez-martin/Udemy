{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Artificial Neural Network: Churn Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raul/anaconda3/envs/deep_learning/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "X = data_set.iloc[:,3:13].values\n",
    "y = data_set.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "8       4  142051.07              2          0               1   \n",
       "9       2  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the categorical data to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[1])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         3.76000000e+02,   0.00000000e+00,   2.90000000e+01,\n",
       "         4.00000000e+00,   1.15046740e+05,   4.00000000e+00,\n",
       "         1.00000000e+00,   0.00000000e+00,   1.19346880e+05])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply of feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration of the ANN:\n",
    "\n",
    "* Hidden layer 1: inputs --> 11, units(output) --> 6, activation --> Relu\n",
    "* Hidden layer 2: units(output) --> 6, activation --> Relu\n",
    "* Output layer: units(output) --> 1, activation -->\n",
    "\n",
    "**Tip1**: number of units in the hidden(s) layer: average between input and output layers\n",
    "\n",
    "**Tip2**: activation function for the output layer:\n",
    "    * binary: \"sigmoid\"\n",
    "    * multiclass: \"softmax\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                     activation = \"relu\", input_dim = 11))\n",
    "classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                     activation = \"relu\"))\n",
    "classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", \n",
    "                     activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the ANN\n",
    "\n",
    "* Optimizer: stocastic gradient descent \"adam\"\n",
    "* Loss: \"binary_crossentropy\"\n",
    "* Metrics: \"accuracy\"\n",
    "\n",
    "\n",
    "**Tip1**: loss function: \n",
    "* \"binary_crossentropy\" for binary categorical outputs\n",
    "* \"categorical_crossentropy\" for multiclass categorical outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4884 - acc: 0.7940     \n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 0s - loss: 0.4309 - acc: 0.7945     \n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 0s - loss: 0.4248 - acc: 0.8037     \n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4207 - acc: 0.8226     \n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4182 - acc: 0.8275     \n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4169 - acc: 0.8305     \n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4146 - acc: 0.8304     \n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4139 - acc: 0.8319     \n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4125 - acc: 0.8341     \n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4124 - acc: 0.8319     \n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4110 - acc: 0.8334     \n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4104 - acc: 0.8340     \n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4094 - acc: 0.8339     \n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4088 - acc: 0.8352     \n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4084 - acc: 0.8342     \n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4077 - acc: 0.8340     \n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4069 - acc: 0.8349     \n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4072 - acc: 0.8351     \n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4069 - acc: 0.8335     \n",
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 1s - loss: 0.4061 - acc: 0.8344     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7399d8048>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x=X_train, y=y_train, batch_size=10, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation of the model (I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1558,   49],\n",
       "       [ 275,  118]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83799999999999997"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rescale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = sc.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_prediction = classifier.predict(features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False], dtype=bool)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation, Improving and Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    \n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                     activation = \"relu\", input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                     activation = \"relu\"))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", \n",
    "                     activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_cv = KerasClassifier(build_fn=build_classifier, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5175 - acc: 0.7928     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4243 - acc: 0.8065     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4099 - acc: 0.8232     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3995 - acc: 0.8244     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3926 - acc: 0.8272     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3868 - acc: 0.8297     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3826 - acc: 0.8294     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3792 - acc: 0.8308     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3759 - acc: 0.8401     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3728 - acc: 0.8429     \n",
      "480/800 [=================>............] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4885 - acc: 0.7940     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4328 - acc: 0.7947     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4272 - acc: 0.7947     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4226 - acc: 0.8096     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4204 - acc: 0.8231     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4186 - acc: 0.8260     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4171 - acc: 0.8282     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4153 - acc: 0.8307     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4137 - acc: 0.8306     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4135 - acc: 0.8315     \n",
      " 10/800 [..............................] - ETA: 4sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4847 - acc: 0.7968     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4258 - acc: 0.7968     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4197 - acc: 0.8018     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4153 - acc: 0.8278     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4133 - acc: 0.8308     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4113 - acc: 0.8312     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4102 - acc: 0.8333     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4093 - acc: 0.8353     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4081 - acc: 0.8347     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4074 - acc: 0.8354     \n",
      " 10/800 [..............................] - ETA: 4sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4884 - acc: 0.7950     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4312 - acc: 0.7949     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4248 - acc: 0.7947     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4198 - acc: 0.8232     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4177 - acc: 0.8317     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4151 - acc: 0.8326     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4140 - acc: 0.8357     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4131 - acc: 0.8349     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4115 - acc: 0.8362     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4107 - acc: 0.8360     \n",
      " 10/800 [..............................] - ETA: 8sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4992 - acc: 0.7939     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4317 - acc: 0.7949     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4256 - acc: 0.7949     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4214 - acc: 0.8165     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4186 - acc: 0.8279     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4170 - acc: 0.8292     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4152 - acc: 0.8310     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4138 - acc: 0.8328     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4129 - acc: 0.8317     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4121 - acc: 0.8321     \n",
      " 10/800 [..............................] - ETA: 7sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5048 - acc: 0.7901     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4381 - acc: 0.7907     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4324 - acc: 0.7907     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4286 - acc: 0.8044     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4250 - acc: 0.8226     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4234 - acc: 0.8260     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4213 - acc: 0.8287     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4200 - acc: 0.8300     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4185 - acc: 0.8312     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4177 - acc: 0.8306     \n",
      "790/800 [============================>.] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4848 - acc: 0.7939     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4316 - acc: 0.7943     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4255 - acc: 0.7947     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4210 - acc: 0.8233     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4184 - acc: 0.8283     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4167 - acc: 0.8272     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4154 - acc: 0.8307     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4141 - acc: 0.8317     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4131 - acc: 0.8310     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4120 - acc: 0.8322     \n",
      " 10/800 [..............................] - ETA: 8sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4964 - acc: 0.7965     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4274 - acc: 0.7974     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4225 - acc: 0.7974     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4184 - acc: 0.8081     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4153 - acc: 0.8274     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4128 - acc: 0.8328     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.4112 - acc: 0.8339     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4098 - acc: 0.8353     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4086 - acc: 0.8361     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4074 - acc: 0.8378     \n",
      "780/800 [============================>.] - ETA: 0s Epoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4975 - acc: 0.7944     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4158 - acc: 0.8185     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3929 - acc: 0.8379     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3716 - acc: 0.8479     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3586 - acc: 0.8525     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3515 - acc: 0.8594     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3476 - acc: 0.8579     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3452 - acc: 0.8603     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3447 - acc: 0.8589     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3432 - acc: 0.8615     \n",
      "640/800 [=======================>......] - ETA: 0s Epoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4970 - acc: 0.7996     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4166 - acc: 0.8250     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4015 - acc: 0.8296     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3907 - acc: 0.8311     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.3827 - acc: 0.8307     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.3770 - acc: 0.8400     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.3718 - acc: 0.8478     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.3687 - acc: 0.8503     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.3649 - acc: 0.8506     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s - loss: 0.3623 - acc: 0.8524     \n",
      " 10/800 [..............................] - ETA: 18s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "accuracies = cross_val_score(estimator = classifier_cv, X = X_train, \n",
    "                             y = y_train, cv = 10, n_jobs = 1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87249999,  0.84      ,  0.80749999,  0.8125    ,  0.84249999,\n",
       "        0.84624999,  0.84499999,  0.81      ,  0.85749999,  0.85874999])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --> Mean: 0.8392499948665499; Standard Variation: 0.02119256875185233\n"
     ]
    }
   ],
   "source": [
    "mean_accu = accuracies.mean()\n",
    "variance_accu = accuracies.std()\n",
    "print(\"Accuracy --> Mean: {0}; Standard Variation: {1}\".format(mean_accu, variance_accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Improving the ANN\n",
    "\n",
    "### 6.1 Dropout\n",
    "\n",
    "Reduce overfitting, reduce the high variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_drop = Sequential()\n",
    "\n",
    "classifier_drop.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                 activation = \"relu\", input_dim = 11))\n",
    "classifier_drop.add(Dropout(0.1))\n",
    "\n",
    "classifier_drop.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                 activation = \"relu\"))\n",
    "classifier_drop.add(Dropout(0.1))\n",
    "\n",
    "classifier_drop.add(Dense(units = 1, kernel_initializer=\"uniform\", \n",
    "                 activation = \"sigmoid\"))\n",
    "\n",
    "classifier_drop.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Tuning the ANN\n",
    "\n",
    "Parameter tunning --> grid search\n",
    "\n",
    "We are going to tune:\n",
    "\n",
    "* batch_size\n",
    "* epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    \n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                     activation = \"relu\", input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer=\"uniform\", \n",
    "                     activation = \"relu\"))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer=\"uniform\", \n",
    "                     activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_gs = KerasClassifier(build_fn=build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters = {'batch_size': [25, 32],\n",
    "#               'epochs':[10, 20],\n",
    "#               'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs':[10],\n",
    "              'optimizer': ['adam']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=classifier_gs, \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5579 - acc: 0.7919     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4404 - acc: 0.7933     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4349 - acc: 0.7933     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4311 - acc: 0.7933     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4274 - acc: 0.7933     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4242 - acc: 0.7971     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4203 - acc: 0.8226     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4158 - acc: 0.8321     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4121 - acc: 0.8317     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4095 - acc: 0.8332     \n",
      "5575/7200 [======================>.......] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5418 - acc: 0.7947     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4381 - acc: 0.7947     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4316 - acc: 0.7947     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4271 - acc: 0.7947     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4237 - acc: 0.7969     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4209 - acc: 0.8171     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4193 - acc: 0.8215     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4180 - acc: 0.8265     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4168 - acc: 0.8286     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4152 - acc: 0.8304     \n",
      "6900/7200 [===========================>..] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5810 - acc: 0.7956     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4373 - acc: 0.7968     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4305 - acc: 0.7968     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4269 - acc: 0.7968     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4237 - acc: 0.7968     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4212 - acc: 0.7968     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4185 - acc: 0.7975     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4165 - acc: 0.8203     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4148 - acc: 0.8244     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4135 - acc: 0.8267     \n",
      "5100/7200 [====================>.........] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5637 - acc: 0.7933     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4369 - acc: 0.7949     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4295 - acc: 0.7949     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4246 - acc: 0.7981     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4202 - acc: 0.8240     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4159 - acc: 0.8303     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4122 - acc: 0.8333     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4094 - acc: 0.8350     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4074 - acc: 0.8367     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4058 - acc: 0.8360     \n",
      "6500/7200 [==========================>...] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5510 - acc: 0.7943     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4371 - acc: 0.7949     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4310 - acc: 0.7949     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4271 - acc: 0.7949     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4240 - acc: 0.7949     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4217 - acc: 0.8097     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4200 - acc: 0.8242     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4189 - acc: 0.8274     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4181 - acc: 0.8275     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4168 - acc: 0.8311     \n",
      "6025/7200 [========================>.....] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5738 - acc: 0.7890     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4474 - acc: 0.7907     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4404 - acc: 0.7907     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4379 - acc: 0.7907     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4354 - acc: 0.7907     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4328 - acc: 0.7907     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4308 - acc: 0.7967     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4284 - acc: 0.8154     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4265 - acc: 0.8193     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4249 - acc: 0.8228     \n",
      "6700/7200 [==========================>...] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5496 - acc: 0.7943     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4377 - acc: 0.7943     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4307 - acc: 0.7943     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4273 - acc: 0.7943     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4237 - acc: 0.7986     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4214 - acc: 0.8186     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4198 - acc: 0.8251     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4187 - acc: 0.8275     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4174 - acc: 0.8297     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4167 - acc: 0.8310     \n",
      "6250/7200 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5758 - acc: 0.7956     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4372 - acc: 0.7974     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4299 - acc: 0.7974     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4272 - acc: 0.7974     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4245 - acc: 0.7974     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4222 - acc: 0.7974     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4197 - acc: 0.7974     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4175 - acc: 0.8079     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4155 - acc: 0.8211     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4144 - acc: 0.8258     \n",
      "5625/7200 [======================>.......] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5548 - acc: 0.7942     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4388 - acc: 0.7946     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4310 - acc: 0.7946     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4260 - acc: 0.7946     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4211 - acc: 0.8217     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4166 - acc: 0.8312     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4126 - acc: 0.8331     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4098 - acc: 0.8342     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4076 - acc: 0.8356     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4055 - acc: 0.8349     \n",
      "6675/7200 [==========================>...] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 1s - loss: 0.5612 - acc: 0.7926     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4415 - acc: 0.7935     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4363 - acc: 0.7935     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4335 - acc: 0.7935     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4309 - acc: 0.7935     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4286 - acc: 0.7935     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4259 - acc: 0.7983     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4240 - acc: 0.8172     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4225 - acc: 0.8199     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4212 - acc: 0.8228     \n",
      "6400/7200 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5821 - acc: 0.7915     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4423 - acc: 0.7933     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4341 - acc: 0.7933     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4295 - acc: 0.7933     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4265 - acc: 0.8058     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4230 - acc: 0.8199     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4189 - acc: 0.8257     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4159 - acc: 0.8281     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4129 - acc: 0.8299     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4103 - acc: 0.8317     \n",
      "5952/7200 [=======================>......] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5892 - acc: 0.7936     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4464 - acc: 0.7947     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4371 - acc: 0.7947     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4340 - acc: 0.7947     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4319 - acc: 0.7947     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4301 - acc: 0.7947     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4275 - acc: 0.7947     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4251 - acc: 0.7947     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4229 - acc: 0.8046     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4215 - acc: 0.8185     \n",
      "5152/7200 [====================>.........] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5845 - acc: 0.7956     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4397 - acc: 0.7968     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4320 - acc: 0.7968     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4287 - acc: 0.7968     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4257 - acc: 0.7968     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4229 - acc: 0.7968     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4202 - acc: 0.7968     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4178 - acc: 0.8072     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4161 - acc: 0.8226     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4144 - acc: 0.8271     \n",
      "6432/7200 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5911 - acc: 0.7942     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4429 - acc: 0.7949     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4359 - acc: 0.7949     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4340 - acc: 0.7949     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4327 - acc: 0.7949     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4316 - acc: 0.7949     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4306 - acc: 0.7949     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4298 - acc: 0.7949     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4288 - acc: 0.7949     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4271 - acc: 0.7947     \n",
      "4320/7200 [=================>............] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5752 - acc: 0.7949     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4413 - acc: 0.7949     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4359 - acc: 0.7949     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4331 - acc: 0.7949     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4307 - acc: 0.7949     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4285 - acc: 0.7949     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4263 - acc: 0.7949     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4243 - acc: 0.8031     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4231 - acc: 0.8192     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4218 - acc: 0.8203     \n",
      "6560/7200 [==========================>...] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.6095 - acc: 0.7881     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4535 - acc: 0.7907     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4411 - acc: 0.7907     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4369 - acc: 0.7907     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4341 - acc: 0.7907     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4316 - acc: 0.7907     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4295 - acc: 0.7907     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4276 - acc: 0.7986     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4263 - acc: 0.8163     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4248 - acc: 0.8214     \n",
      "6944/7200 [===========================>..] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.6144 - acc: 0.7926     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4468 - acc: 0.7946     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4282 - acc: 0.8086     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4237 - acc: 0.8187     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4209 - acc: 0.8210     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4186 - acc: 0.8215     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4166 - acc: 0.8232     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4148 - acc: 0.8236     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4129 - acc: 0.8264     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4110 - acc: 0.8258     \n",
      "7040/7200 [============================>.] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5950 - acc: 0.7967     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4381 - acc: 0.7974     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4291 - acc: 0.7974     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4255 - acc: 0.7974     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4229 - acc: 0.7974     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4204 - acc: 0.7974     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4181 - acc: 0.7974     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4161 - acc: 0.8111     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4148 - acc: 0.8265     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4135 - acc: 0.8282     \n",
      "7136/7200 [============================>.] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.6056 - acc: 0.7932     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4454 - acc: 0.7946     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4356 - acc: 0.7946     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4328 - acc: 0.7946     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4310 - acc: 0.7946     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4289 - acc: 0.7946     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4269 - acc: 0.7946     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4250 - acc: 0.7946     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4232 - acc: 0.8056     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4217 - acc: 0.8165     \n",
      "5600/7200 [======================>.......] - ETA: 0sEpoch 1/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.5853 - acc: 0.7935     \n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4461 - acc: 0.7935     \n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4379 - acc: 0.7935     \n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4344 - acc: 0.7935     \n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4319 - acc: 0.7935     \n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4288 - acc: 0.7935     \n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4260 - acc: 0.7935     \n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4237 - acc: 0.8125     \n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4225 - acc: 0.8174     \n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 0s - loss: 0.4210 - acc: 0.8225     \n",
      "6336/7200 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.5581 - acc: 0.7931     \n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4408 - acc: 0.7945     \n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4335 - acc: 0.7945     \n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4306 - acc: 0.7945     \n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4271 - acc: 0.7945     \n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4237 - acc: 0.7991     \n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4210 - acc: 0.8202     \n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4191 - acc: 0.8221     \n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4178 - acc: 0.8265     \n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 0s - loss: 0.4164 - acc: 0.8272     \n"
     ]
    }
   ],
   "source": [
    "grid_search_fit = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_parameters = grid_search_fit.best_params_\n",
    "best_accuracy = grid_search_fit.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'optimizer': 'adam', 'epochs': 10, 'batch_size': 25}\n",
      "Best Accuracies: 0.830375\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: {0}\".format(best_parameters))\n",
    "print(\"Best Accuracies: {0}\".format(best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
